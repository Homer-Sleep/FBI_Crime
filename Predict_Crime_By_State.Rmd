---
title: "FBI_Crime_Supervised"
author: "Dave"
date: "3/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr)
library(papeR)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(tidyr)
library(readxl)
library(data.table)
# library(foreign)
# library(multcomp)
# library(broom)
# library(nlme)
library(tidyverse)
# library(stargazer)
# library(reshape2)
# library(rmarkdown)
# library(psych)
library(RColorBrewer)
# library(minpack.lm)
# library(numDeriv)
# # library(mosaic)
# library(pracma)
# library(formattable)
# library(lme4)
# library(sjPlot)
# library(emmeans)
# library(Cairo) # Cleans up plot Alias CairoWIN() use ggsave "cairo-png"
knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")))

```



Get dataset from FBI
```{r}
# each xls sheet has that year and the previous year. Download 2010, 2012, 2014, 2016. 2018, 2019
urls = c('https://ucr.fbi.gov/crime-in-the-u.s/2010/crime-in-the-u.s.-2010/tables/10tbl04.xls/output.xls',
         'https://ucr.fbi.gov/crime-in-the-u.s/2012/crime-in-the-u.s.-2012/tables/4tabledatadecoverviewpdf/table_4_crime_in_the_united_states_by_region_geographic_division_and_state_2011-2012.xls/output.xls',
         'https://ucr.fbi.gov/crime-in-the-u.s/2014/crime-in-the-u.s.-2014/tables/table-4/table_4_crime_in_the_united_states_by_region_geographic_division_and_state_2013-2014.xls/output.xls',
         'https://ucr.fbi.gov/crime-in-the-u.s/2016/crime-in-the-u.s.-2016/tables/table-2/table-2.xls/output.xls',
         'https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/table-4/table-4.xls/output.xls',
         'https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/tables/table-4/table-4.xls/output.xls')
Year.crime = list()
 for (i in seq_along(urls)) {

  Crime.raw = NULL
  ################### if statement to find if file is in WD, if not download######################
  download.file(urls[i], 'tmp.xls', mode = 'wb') # download xls from FBI website
  Crime.raw = data.table(read_excel('tmp.xls', skip = 3)) # read into data.table
  # Crime.raw = data.table(read_excel('10tbl04.xls', skip = 3)) # read into data.table
  # remove empty columns
  Crime.raw = Crime.raw[,which(unlist(lapply(Crime.raw, function(x)!all(is.na(x))))),with=F]
  
  # rename cols to be the same across data sets
  # fix these names: "Population1" "Violent crime_Per100k" "Murder and\nnonnegligent\nmanslaughter_Per100k" "Forcible rape_Per100k"                         
  pop.fix = startsWith(colnames(Crime.raw), prefix = 'Pop')
  setnames(Crime.raw, colnames(Crime.raw[,..pop.fix]), 'Population')
  pop.fix = startsWith(colnames(Crime.raw), prefix = 'Murder')
  setnames(Crime.raw, colnames(Crime.raw[,..pop.fix]), 'Murder')
  pop.fix = startsWith(colnames(Crime.raw), prefix = 'Violent')
  setnames(Crime.raw, colnames(Crime.raw[,..pop.fix]), 'Violent.Crime')
  
  ############## i = 3 Rape has two types legacy and revised ######################
  pop.fix = startsWith(colnames(Crime.raw), prefix = 'Forcible')
  if(sum(pop.fix) > 1){pop.fix = startsWith(colnames(Crime.raw), prefix = 'Rape')}
  setnames(Crime.raw, colnames(Crime.raw[,..pop.fix]), 'Rape')
  
  #rename columns leading with '..#'
  # find col with Name
  col.names = colnames(Crime.raw)
  for (col.i in seq_along(col.names)) {
    if (startsWith(col.names[col.i], prefix = '..')){ # rename cols that start with '..' to _Per100k'
      col.names[col.i] = paste0(col.names[col.i -1], '_Per100k')
      }
    }
  setnames(Crime.raw, names(Crime.raw),  col.names) # rename 
  
  # remove extra cols if any
  rm.col=  !endsWith(colnames(Crime.raw), suffix = '_Per100k_Per100k') # extra cols will have extra per100k
  Crime.raw = Crime.raw[,..rm.col]# remove cols
  
  #remove cols of raw numbers, leave per100k for comparisons across states
  rm.col = endsWith(colnames(Crime.raw), suffix = '_Per100k')
  rm.col[1:3] = TRUE # keep first 3 rows of Area, year and population 
  Crime.raw = Crime.raw[,..rm.col]
  # Remove numbers  and comma from Area
  Crime.raw$Area = gsub('[0-9]', '', Crime.raw$Area)
  Crime.raw$Area = gsub(',', '', Crime.raw$Area)

  # edit rows:
  Crime.raw = Crime.raw[Year != 'Percent change']# remove percent change rows
  
  # If Area name is NA, rename it to row above
  for (ii in 1:Crime.raw[,.N]) {
      if (is.na(Crime.raw[ii, 1])){
      Crime.raw[ii, 1] = Crime.raw[ii-1, 1]
    }
  }
  # change to numeric
  Crime.raw[,2:ncol(Crime.raw)] = as.data.table(sapply(Crime.raw[,2:ncol(Crime.raw)], as.numeric))
  
  ################# Round each col, I have a function for this ###########################
    Crime.raw %>% mutate_if(is.numeric, ~round(., digit = 2))  

  two.years = unique(Crime.raw$Year)
  Year.crime[[two.years[1]]] = Crime.raw[Year == two.years[1]]
  Year.crime[[two.years[2]]] = Crime.raw[Year == two.years[2]]
  
  if (!exists('Crime')){
    Crime = Crime.raw
  }else{
    colnames(Crime.raw)
    Crime2 = 
      merge.data.table(Crime, Crime.raw, by = colnames(Crime), all= TRUE)
    setdiff (colnames(Crime), colnames(Crime.raw))
  }
}
  
```
 
I have crime by state, and region in time series (2009 - 2019). 
Use 2009 - 2017 as training set, 2018 & 2019 as test set. 
What do I want to predict? 
Unsupervised first? 
1) PCA - maybe find another feature to make predictions? 
2) Herarchical Clusters
